{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) TranAn. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "Email: tranandeveloper@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cài đặt package và kết nối với Workspace\n",
    "\n",
    "***Trong notebook này bạn sẽ học được cách kết nối đến workspace của bạn và khởi tạo jobs cho workspace***\n",
    "\n",
    "***Lưu ý***: Để có thể chạy được notebook này hãy chắc chắn rằng bạn đã khởi tạo được workspace. Nếu không hãy xem lại bài đầu tiên để khởi tạo.\n",
    "\n",
    "**Yêu cầu**: Đã cài đặt đầy đủ dependencies. Đối với Azure ml yêu cầu python > 3.7. Chưa cài đặt có thể cài qua lệnh\n",
    "\n",
    "```\n",
    "pip install azure-ai-ml\n",
    "```\n",
    "\n",
    "> Hãy thay key value cho subcriptions của bạn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"<my-subscription-id>\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"<my-resource-group>\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"<my-workspace-name>\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"eastus2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Kết nối với Azure Machine Learning Client\n",
    "- credential: Là gói xác thực hiện tại đang để Default\n",
    "\n",
    "Hãy chắc chắn rằng bạn đã xác thực cả AzureCLI ```azd auth login```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tạo compute\n",
    "---\n",
    "\n",
    "**Lý do**: Tại sao phải tạo computer? Hiểu đơn giản ở đây dù bạn đã khởi tạo dịch vụ AzureML nhưng đó mới chỉ là bạn đăng ký để sử dụng. Các tài nguyên sẽ được quản lý trong dịch vụ đó. Khi bạn muốn train, predict, xử lý dữ liệu,... bạn cần tài nguyên hoặc máy chủ computer. Việc cần thiết ở đây là bạn phải lựa chọn và khởi tạo cấu hình dịch vụ computer mà bạn mong muốn để chạy yêu cầu của bạn.\n",
    "\n",
    "**Các bước khởi tạo**\n",
    "1. Từ màn hình chính của AzureML Studio lựa chọn Manage/computer\n",
    "2. Ở đây có nhiều dịch vụ computer phù hợp cho từng tác vụ khác nhau. (ở đây chúng ta đang thử nghiệm đào tạo và develop nên tôi khuyên bạn chọn compute instance)\n",
    "3. Lựa chọn cài đặt cấu hình mong muốn và ấn nút create\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_NAME = os.getenv(\"COMPUTE_NAME\", default=\"<Name>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khởi tạo compute bằng Azure CLI\n",
    "---\n",
    "\n",
    "***Lưu ý***: Hãy chắc chắn rằng bạn đã cài đặt AzureCLI trên máy của mình hoặc sử dụng Azure Cloud Shell. Cho dù bạn dùng platform nào thì các chức năng nó cũng hoàn toàn giống nhau. Sau khi cài đặt AzureCLI bạn cần phải cài đặt AzureML extensions để có thể quản lý được Azure Machine Learning resources của bạn.\n",
    "\n",
    "1. Cài đặt AzureML extension qua lệnh sau:\n",
    "    ```\n",
    "    az extension add -n ml -y\n",
    "    ```\n",
    "    Sau khi cài đặt thành công bạn có thể thử dụng lệnh ```-h``` để kiểm tra xem extension đã được cài đặt hay chưa và lấy danh sách hỗ trợ tính năng của extentions này.\n",
    "\n",
    "2. Sau khi cài đặt bạn có thể tương tác với Azure Machine Learning Workspace bằng lệnh cmd. Từng lệnh cmd đều có tiền tố ```az ml``` đứng trước để xác định rằng đang sử dụng AzureML extension.\n",
    "\n",
    "***Ví dụ***: Bạn có thể khởi tạo mục tiêu compute cluster của mình với lệnh cmd dưới đây: \n",
    "```\n",
    "az ml compute create --name aml-cluster --size <name virtual machine> --min-instances 0 --max-instances 5 --type AmlCompute --resource-group <name-your-resource-group> --workspace-name <name-your-workspace>\n",
    "```\n",
    "**Hoặc**: Bạn hoàn toàn có thể sử dụng tệp yaml để cấu hình cho compute của mình:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting compute_cluster.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile compute_cluster.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/amlCompute.schema.json \n",
    "name: aml-cluster\n",
    "type: amlcompute\n",
    "size: <name-of-vm-size>\n",
    "min_instances: 0\n",
    "max_instances: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó bạn chạy lệnh dưới đây để build compute của bạn:\n",
    "```\n",
    "az ml compute create --file <name-file-yml>.yml --resource-group <name-your-resource-group> --workspace-name <name-your-workspace>\n",
    "```\n",
    "\n",
    "***Lưu ý***: Phải chạy đúng path nơi để file yml\n",
    "> Bạn có thể tìm thấy thêm cài đặt file yml <a href=\"https://learn.microsoft.com/en-us/azure/machine-learning/reference-yaml-overview?view=azureml-api-2\">tại đây</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tạo môi trường cho job\n",
    "\n",
    "Để chạy một job trong AzureML bạn cần đến một môi trường. Có thể tìm kiếm môi trường phù hợp trong Environmentstại cổng AzureMLStudio\n",
    "\n",
    "Ở notebook này tôi sẽ ví dụ sử dụng môi trường ```AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest``` vì nó có chứa các thư viện cơ bản cần thiết cho ML như (python, MLflow, numpy, pip, etc).\n",
    "\n",
    "# Khởi tạo Job để huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo vùng chứa cho job\n",
    "import os\n",
    "\n",
    "train_src_dir = \"./src\"\n",
    "os.makedirs(train_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {train_src_dir}/main.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
    "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
    "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
    "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
    "    args = parser.parse_args()\n",
    "   \n",
    "    # start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    ###################\n",
    "    #<prepare the data>\n",
    "    ###################\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "    \n",
    "    credit_df = pd.read_csv(args.data, header=1, index_col=0)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        credit_df,\n",
    "        test_size=args.test_train_ratio,\n",
    "    )\n",
    "    ###################\n",
    "    #</prepare the data>\n",
    "    ###################\n",
    "\n",
    "    ##################\n",
    "    #<train the model>\n",
    "    ##################\n",
    "    # extracting the label column\n",
    "    y_train = train_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_train = train_df.values\n",
    "\n",
    "    # extracting the label column\n",
    "    y_test = test_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_test = test_df.values\n",
    "\n",
    "    print(f\"Training with data of shape {X_train.shape}\")\n",
    "\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    ##################\n",
    "    #</train the model>\n",
    "    ##################\n",
    "\n",
    "    ##########################\n",
    "    #<save and register model>\n",
    "    ##########################\n",
    "    # registering the model to the workspace\n",
    "    print(\"Registering the model via MLFlow\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=clf,\n",
    "        registered_model_name=args.registered_model_name,\n",
    "        artifact_path=args.registered_model_name,\n",
    "    )\n",
    "\n",
    "    # saving the model to a file\n",
    "    mlflow.sklearn.save_model(\n",
    "        sk_model=clf,\n",
    "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
    "    )\n",
    "    \n",
    "    # stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# name the model you registered earlier in the training script\n",
    "registered_model_name = \"credit_defaults_model\"\n",
    "\n",
    "# configure the command job\n",
    "job = command(\n",
    "    inputs=dict(\n",
    "        # uri_file refers to a specific file as a data asset\n",
    "        data=Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"https://azuremlexamples.blob.core.windows.net/datasets/credit_card/default%20of%20credit%20card%20clients.csv\",\n",
    "        ),\n",
    "        test_train_ratio=0.2,  # input variable in main.py\n",
    "        learning_rate=0.25,  # input variable in main.py\n",
    "        registered_model_name=registered_model_name,  # input variable in main.py\n",
    "    ),\n",
    "    code=\"./src/\",  # location of source code\n",
    "    # The inputs/outputs are accessible in the command via the ${{ ... }} notation\n",
    "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
    "    # This is the ready-made environment you are using\n",
    "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n",
    "    # This is the compute you created earlier. You can alternatively remove this line to use serverless compute to run the job\n",
    "    compute=COMPUTE_NAME,\n",
    "    # An experiment is a container for all the iterations one does on a certain project. All the jobs submitted under the same experiment name would be listed next to each other in Azure ML studio.\n",
    "    experiment_name=\"train_model_credit_default_prediction\",\n",
    "    display_name=\"credit_default_prediction\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the command job\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Code ví dụ được lấy tại Microsoft SDK. Truy cập vào AzureML sdk để lấy thêm dữ liệu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
